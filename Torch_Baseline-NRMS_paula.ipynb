{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Constants\n",
    "MAX_SENT_LENGTH = 30\n",
    "MAX_SENTS = 50\n",
    "EMBEDDING_DIM = 300\n",
    "NUM_HEADS = 20\n",
    "HEAD_SIZE = 20\n",
    "DROPOUT_RATE = 0.2\n",
    "NPRATIO = 4  # Number of negative samples per positive\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "articles = pd.read_csv(\"Data/articles.csv\")\n",
    "behaviors_train = pd.read_csv(\"Data/behaviors_train.csv\")\n",
    "behaviors_val = pd.read_csv(\"Data/behaviors_val.csv\")\n",
    "history_train = pd.read_csv(\"Data/history_train.csv\")\n",
    "history_val = pd.read_csv(\"Data/history_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2023-05-21 21:06:50\n",
      "1       2023-05-24 07:31:26\n",
      "2       2023-05-24 07:30:33\n",
      "3       2023-05-23 05:25:40\n",
      "4       2023-05-23 05:31:54\n",
      "                ...        \n",
      "24719   2023-05-22 08:30:52\n",
      "24720   2023-05-22 08:31:34\n",
      "24721   2023-05-22 08:51:33\n",
      "24722   2023-05-22 08:53:36\n",
      "24723   2023-05-18 10:56:49\n",
      "Name: impression_time, Length: 24724, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(behaviors_train['impression_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Tokenize article titles and build vocabulary\n",
    "def build_vocab_and_tokenize(titles, max_len=MAX_SENT_LENGTH):\n",
    "    vocab = defaultdict(lambda: len(vocab))  # Default dictionary for token ids\n",
    "    vocab[\"<PAD>\"] = 0  # Padding token\n",
    "    vocab[\"<UNK>\"] = 1  # Unknown token\n",
    "\n",
    "    VOCAB_SIZE = len(vocab)\n",
    "\n",
    "    tokenized_titles = []\n",
    "    for title in titles:\n",
    "        tokens = title.lower().split()[:max_len]  # Simple whitespace tokenizer, truncate to max_len\n",
    "        tokenized = [vocab[token] for token in tokens]\n",
    "        tokenized = [min(idx, VOCAB_SIZE - 1) for idx in tokenized]  # Ensure indices are valid\n",
    "        padded = tokenized + [vocab[\"<PAD>\"]] * (max_len - len(tokenized))  # Padding to max_len\n",
    "        tokenized_titles.append(padded)\n",
    "\n",
    "    return tokenized_titles, vocab, VOCAB_SIZE\n",
    "\n",
    "articles[\"tokenized_title\"], vocab, VOCAB_SIZE = build_vocab_and_tokenize(articles[\"title\"].fillna(\"<UNK>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>impression_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>impression_time</th>\n",
       "      <th>read_time</th>\n",
       "      <th>scroll_percentage</th>\n",
       "      <th>device_type</th>\n",
       "      <th>article_ids_inview</th>\n",
       "      <th>article_ids_clicked</th>\n",
       "      <th>user_id</th>\n",
       "      <th>...</th>\n",
       "      <th>postcode</th>\n",
       "      <th>age</th>\n",
       "      <th>is_subscriber</th>\n",
       "      <th>session_id</th>\n",
       "      <th>next_read_time</th>\n",
       "      <th>next_scroll_percentage</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>time_of_day_bin</th>\n",
       "      <th>normalized_scroll_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>48401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-21 21:06:50</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[9774516 9771051 9770028 9775402 9774461 97595...</td>\n",
       "      <td>[9759966]</td>\n",
       "      <td>22779</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>16.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6</td>\n",
       "      <td>evening</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>152513</td>\n",
       "      <td>9778745.0</td>\n",
       "      <td>2023-05-24 07:31:26</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[9778669 9778736 9778623 9089120 9778661 97774...</td>\n",
       "      <td>[9778661]</td>\n",
       "      <td>150224</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>298</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>155390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-24 07:30:33</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[9778369 9777856 9778500 9778021 9778627 97783...</td>\n",
       "      <td>[9777856]</td>\n",
       "      <td>160892</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>401</td>\n",
       "      <td>215.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>214679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-23 05:25:40</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[9776715 9776406 9776566 9776071 9776808 97762...</td>\n",
       "      <td>[9776566]</td>\n",
       "      <td>1001055</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1357</td>\n",
       "      <td>40.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>night</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>214681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-05-23 05:31:54</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>[9775202 9776855 9776688 9771995 9776583 97765...</td>\n",
       "      <td>[9776553]</td>\n",
       "      <td>1001055</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1358</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>night</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  impression_id  article_id     impression_time  read_time  \\\n",
       "0           0          48401         NaN 2023-05-21 21:06:50       21.0   \n",
       "1           1         152513   9778745.0 2023-05-24 07:31:26       30.0   \n",
       "2           2         155390         NaN 2023-05-24 07:30:33       45.0   \n",
       "3           3         214679         NaN 2023-05-23 05:25:40       33.0   \n",
       "4           4         214681         NaN 2023-05-23 05:31:54       21.0   \n",
       "\n",
       "   scroll_percentage  device_type  \\\n",
       "0                NaN            2   \n",
       "1              100.0            1   \n",
       "2                NaN            1   \n",
       "3                NaN            2   \n",
       "4                NaN            2   \n",
       "\n",
       "                                  article_ids_inview article_ids_clicked  \\\n",
       "0  [9774516 9771051 9770028 9775402 9774461 97595...           [9759966]   \n",
       "1  [9778669 9778736 9778623 9089120 9778661 97774...           [9778661]   \n",
       "2  [9778369 9777856 9778500 9778021 9778627 97783...           [9777856]   \n",
       "3  [9776715 9776406 9776566 9776071 9776808 97762...           [9776566]   \n",
       "4  [9775202 9776855 9776688 9771995 9776583 97765...           [9776553]   \n",
       "\n",
       "   user_id  ...  postcode  age  is_subscriber  session_id  next_read_time  \\\n",
       "0    22779  ...       NaN  NaN          False          21            16.0   \n",
       "1   150224  ...       NaN  NaN          False         298             2.0   \n",
       "2   160892  ...       NaN  NaN          False         401           215.0   \n",
       "3  1001055  ...       NaN  NaN          False        1357            40.0   \n",
       "4  1001055  ...       NaN  NaN          False        1358             5.0   \n",
       "\n",
       "   next_scroll_percentage  day_of_week  time_of_day  time_of_day_bin  \\\n",
       "0                    27.0            6      evening                2   \n",
       "1                    48.0            2      morning                0   \n",
       "2                   100.0            2      morning                0   \n",
       "3                    47.0            1        night                3   \n",
       "4                    49.0            1        night                3   \n",
       "\n",
       "  normalized_scroll_percentage  \n",
       "0                          NaN  \n",
       "1                          1.0  \n",
       "2                          NaN  \n",
       "3                          NaN  \n",
       "4                          NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define preprocessing function\n",
    "def preprocess_behaviors(dataframe):\n",
    "    # Ensure impression_time is in datetime format\n",
    "    dataframe[\"impression_time\"] = pd.to_datetime(dataframe[\"impression_time\"])\n",
    "    \n",
    "    # Extract day of the week (0 = Monday, ..., 6 = Sunday)\n",
    "    dataframe[\"day_of_week\"] = dataframe[\"impression_time\"].dt.dayofweek\n",
    "\n",
    "    # Extract time of day bins\n",
    "    def time_of_day_bin(hour):\n",
    "        if 6 <= hour < 12:\n",
    "            return \"morning\"\n",
    "        elif 12 <= hour < 18:\n",
    "            return \"afternoon\"\n",
    "        elif 18 <= hour < 24:\n",
    "            return \"evening\"\n",
    "        else:\n",
    "            return \"night\"\n",
    "    \n",
    "    dataframe[\"time_of_day\"] = dataframe[\"impression_time\"].dt.hour.apply(time_of_day_bin)\n",
    "    \n",
    "    # Map time of day bins to integers for embedding\n",
    "    time_of_day_mapping = {\"morning\": 0, \"afternoon\": 1, \"evening\": 2, \"night\": 3}\n",
    "    dataframe[\"time_of_day_bin\"] = dataframe[\"time_of_day\"].map(time_of_day_mapping)\n",
    "    \n",
    "    # Normalize scroll percentage to range [0, 1]\n",
    "    dataframe[\"normalized_scroll_percentage\"] = dataframe[\"scroll_percentage\"] / 100.0\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "behaviors_train = preprocess_behaviors(behaviors_train)\n",
    "\n",
    "behaviors_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Clean and process user history\n",
    "def clean_article_ids(article_ids):\n",
    "    try:\n",
    "        if \"...\" in article_ids:\n",
    "            return None  # Mark for removal\n",
    "        return list(map(int, article_ids.strip(\"[]\").split()))\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "history_train[\"cleaned_article_ids\"] = history_train[\"article_id_fixed\"].apply(clean_article_ids)\n",
    "history_val[\"cleaned_article_ids\"] = history_val[\"article_id_fixed\"].apply(clean_article_ids)\n",
    "\n",
    "history_train_cleaned = history_train.dropna(subset=[\"cleaned_article_ids\"]).reset_index(drop=True)\n",
    "history_val_cleaned = history_val.dropna(subset=[\"cleaned_article_ids\"]).reset_index(drop=True)\n",
    "\n",
    "def process_cleaned_user_history(cleaned_history_df):\n",
    "    user_histories = defaultdict(list)\n",
    "    for _, row in cleaned_history_df.iterrows():\n",
    "        user_id = row[\"user_id\"]\n",
    "        article_ids = row[\"cleaned_article_ids\"]\n",
    "        user_histories[user_id].extend(article_ids)\n",
    "    return user_histories\n",
    "\n",
    "user_history_train_cleaned = process_cleaned_user_history(history_train_cleaned)\n",
    "user_history_val_cleaned = process_cleaned_user_history(history_val_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create samples and labels\n",
    "def create_samples(behaviors_df, user_history, max_sents=MAX_SENTS):\n",
    "    samples = []\n",
    "    labels = []\n",
    "    for _, row in behaviors_df.iterrows():\n",
    "        user_id = row[\"user_id\"]\n",
    "        clicked_articles = list(map(int, row[\"article_ids_clicked\"].strip(\"[]\").split()))\n",
    "        inview_articles = list(map(int, row[\"article_ids_inview\"].strip(\"[]\").split()))\n",
    "\n",
    "        user_hist = user_history[user_id][:max_sents] + [0] * (max_sents - len(user_history[user_id]))\n",
    "        user_hist = [min(idx, VOCAB_SIZE - 1) for idx in user_hist]  # Ensure valid indices\n",
    "\n",
    "        for article_id in inview_articles:\n",
    "            article_id = min(article_id, VOCAB_SIZE - 1)  # Ensure valid index\n",
    "            label = 1 if article_id in clicked_articles else 0\n",
    "            samples.append((user_hist, article_id))\n",
    "            labels.append(label)\n",
    "\n",
    "    return samples, labels\n",
    "\n",
    "train_samples_cleaned, train_labels_cleaned = create_samples(behaviors_train, user_history_train_cleaned)\n",
    "val_samples_cleaned, val_labels_cleaned = create_samples(behaviors_val, user_history_val_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Define PyTorch Dataset\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, samples, labels):\n",
    "        self.samples = samples\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user_history, candidate = self.samples[idx]\n",
    "        user_history_padded = [0] * MAX_SENTS  # Pad user history\n",
    "        user_history_padded[:len(user_history)] = user_history[:MAX_SENTS]\n",
    "        candidate_padded = [candidate] + [0] * (MAX_SENT_LENGTH - 1)  # Pad candidate to sequence\n",
    "        return (\n",
    "            torch.tensor(user_history_padded, dtype=torch.long),\n",
    "            torch.tensor(candidate_padded, dtype=torch.long),\n",
    "            torch.tensor(self.labels[idx], dtype=torch.long),\n",
    "        )\n",
    "\n",
    "train_dataset = NewsDataset(train_samples_cleaned, train_labels_cleaned)\n",
    "val_dataset = NewsDataset(val_samples_cleaned, val_labels_cleaned)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define the NRMS Model\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_size = head_size\n",
    "        self.output_dim = num_heads * head_size\n",
    "        self.qkv_linear = nn.Linear(EMBEDDING_DIM, self.output_dim * 3)\n",
    "        self.fc_out = nn.Linear(self.output_dim, EMBEDDING_DIM)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.size()) != 3:\n",
    "            raise ValueError(f\"Expected input to be 3D (batch_size, seq_length, embed_dim), got {x.size()}\")\n",
    "        batch_size, seq_length, embed_dim = x.size()\n",
    "        qkv = self.qkv_linear(x).reshape(batch_size, seq_length, self.num_heads, 3 * self.head_size)\n",
    "        qkv = qkv.permute(2, 0, 1, 3)\n",
    "        Q, K, V = torch.chunk(qkv, 3, dim=-1)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.head_size)\n",
    "        attention = F.softmax(scores, dim=-1)\n",
    "        weighted = torch.matmul(attention, V)\n",
    "        return self.fc_out(weighted.permute(1, 2, 0, 3).reshape(batch_size, seq_length, self.output_dim))\n",
    "\n",
    "class TitleEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.dropout = nn.Dropout(DROPOUT_RATE)\n",
    "        self.self_attention = MultiHeadSelfAttention(NUM_HEADS, HEAD_SIZE)\n",
    "        self.dense = nn.Linear(embedding_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # Ensure input is embedded\n",
    "        if len(x.size()) != 3:\n",
    "            raise ValueError(f\"Embedding layer output should be 3D, got {x.size()}\")\n",
    "        x = self.dropout(x)\n",
    "        x = self.self_attention(x)\n",
    "        attention_weights = F.softmax(self.dense(x).squeeze(-1), dim=-1)\n",
    "        return torch.sum(x * attention_weights.unsqueeze(-1), dim=1)\n",
    "\n",
    "class NRMS(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.title_encoder = TitleEncoder(vocab_size, embedding_dim)\n",
    "\n",
    "    def forward(self, candidates, user_history):\n",
    "        user_rep = self.title_encoder(user_history)  # Output: (batch_size, embedding_dim)\n",
    "        candidate_rep = self.title_encoder(candidates)  # Output: (batch_size, embedding_dim)\n",
    "        return torch.matmul(candidate_rep, user_rep.unsqueeze(-1)).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Train the Model\n",
    "model = NRMS(VOCAB_SIZE, EMBEDDING_DIM, NPRATIO + 1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, epochs=EPOCHS):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            user_histories, candidates, labels = batch\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(candidates, user_histories)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/paulagranlund/Documents/GitHub/New-Recommendation-NRMS/Torch_Baseline-NRMS_3.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/paulagranlund/Documents/GitHub/New-Recommendation-NRMS/Torch_Baseline-NRMS_3.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/paulagranlund/Documents/GitHub/New-Recommendation-NRMS/Torch_Baseline-NRMS_3.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_model(model, train_loader, val_loader, optimizer, criterion)\n",
      "\u001b[1;32m/Users/paulagranlund/Documents/GitHub/New-Recommendation-NRMS/Torch_Baseline-NRMS_3.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulagranlund/Documents/GitHub/New-Recommendation-NRMS/Torch_Baseline-NRMS_3.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(candidates, user_histories)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulagranlund/Documents/GitHub/New-Recommendation-NRMS/Torch_Baseline-NRMS_3.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/paulagranlund/Documents/GitHub/New-Recommendation-NRMS/Torch_Baseline-NRMS_3.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulagranlund/Documents/GitHub/New-Recommendation-NRMS/Torch_Baseline-NRMS_3.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulagranlund/Documents/GitHub/New-Recommendation-NRMS/Torch_Baseline-NRMS_3.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Documents/GitHub/New-Recommendation-NRMS/.venv/lib/python3.9/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    582\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    583\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/New-Recommendation-NRMS/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[1;32m    348\u001b[0m     tensors,\n\u001b[1;32m    349\u001b[0m     grad_tensors_,\n\u001b[1;32m    350\u001b[0m     retain_graph,\n\u001b[1;32m    351\u001b[0m     create_graph,\n\u001b[1;32m    352\u001b[0m     inputs,\n\u001b[1;32m    353\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    354\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/New-Recommendation-NRMS/.venv/lib/python3.9/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[39m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m         t_outputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    827\u001b[0m     )  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[39mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, optimizer, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
