{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Hf6wMwHBqC9",
        "outputId": "29b78662-b40e-4e0d-8d60-6cef5ebe8cbc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     /Users/annemoll/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "#from google.colab import drive\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOr77FWMBrBs",
        "outputId": "fe89b5d1-1c72-483c-b185-d51256f1d483"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9VkRememCDIq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Set the device to GPU if available, otherwise CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7V-q8GrAE3x",
        "outputId": "620c5cab-d6d1-4b8f-bdc2-28a794a8c371"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique articles: 11777\n",
            "Example article ID and tokenized title:\n",
            "Article ID: 3037230, Tokenized Title: ['ishockey-spiller', ':', 'jeg', 'troede', 'jeg', 'skulle', 'dø']\n",
            "Article ID: 3044020, Tokenized Title: ['prins', 'harry', 'tvunget', 'til', 'dna-test']\n",
            "Article ID: 3057622, Tokenized Title: ['rådden', 'kørsel', 'på', 'blå', 'plader']\n",
            "\n",
            "Total articles indexed in newsindex: 11778 \n",
            "\n",
            "Training Data:\n",
            "Number of training candidates: 24888\n",
            "Number of training labels: 24888\n",
            "Number of user histories: 24888\n",
            "\n",
            "Validation Data:\n",
            "Number of validation candidates: 25505\n",
            "Number of validation labels: 25505\n",
            "Number of user histories: 25505\n"
          ]
        }
      ],
      "source": [
        "MAX_TITLE_LEN = 20\n",
        "\n",
        "articles_path = 'Data/articles.parquet'\n",
        "behaviors_train_path = 'Data/behaviors_train.parquet'\n",
        "behaviors_val_path = 'Data/behaviors_val.parquet'\n",
        "history_train_path = 'Data/history_train.parquet'\n",
        "history_val_path = 'Data/history_val.parquet'\n",
        "\n",
        "# Load data from Parquet files\n",
        "articles = pd.read_parquet(articles_path)\n",
        "train_behaviors = pd.read_parquet(behaviors_train_path)\n",
        "val_behaviors = pd.read_parquet(behaviors_val_path)\n",
        "history_train = pd.read_parquet(history_train_path)\n",
        "history_val = pd.read_parquet(history_val_path)\n",
        "\n",
        "# Create a news dict and  article_id to a unique index\n",
        "news = {}\n",
        "newsindex = {'NULL': 0}  # Add a NULL key for padding\n",
        "for idx, row in articles.iterrows():\n",
        "    article_id = row['article_id']\n",
        "    title = row['title'].lower()\n",
        "    tokenized_title = word_tokenize(title)\n",
        "\n",
        "    news[article_id] = tokenized_title\n",
        "    newsindex[article_id] = len(newsindex)\n",
        "\n",
        "# Summary\n",
        "print(\"Number of unique articles:\", len(news))\n",
        "print(\"Example article ID and tokenized title:\")\n",
        "for k, v in list(news.items())[:3]:  # Print first 3 articles\n",
        "    print(f\"Article ID: {k}, Tokenized Title: {v}\")\n",
        "\n",
        "print(\"\\nTotal articles indexed in newsindex:\", len(newsindex), \"\\n\")\n",
        "\n",
        "\n",
        "# Helper function to sample negative examples\n",
        "def newsample(array, ratio):\n",
        "    if len(array) == 0:\n",
        "        return []\n",
        "    if ratio > len(array):\n",
        "        return random.sample(array * (ratio // len(array) + 1), ratio)\n",
        "    else:\n",
        "        return random.sample(array, ratio)\n",
        "\n",
        "# Sampling configuration\n",
        "npratio = 4  # Number of negative samples per positive sample\n",
        "MAX_HISTORY_LEN = 50\n",
        "\n",
        "# Function to process behaviors data\n",
        "def process_behaviors(behaviors, newsindex, history_data=None):\n",
        "    train_candidate = []\n",
        "    train_label = []\n",
        "    train_user_his = []\n",
        "\n",
        "    # Build a user history dictionary from history data if provided\n",
        "    user_history = {}\n",
        "    if history_data is not None:\n",
        "        for _, row in history_data.iterrows():\n",
        "            user_history[row['user_id']] = [newsindex.get(aid, 0) for aid in row['article_id_fixed']]\n",
        "\n",
        "    for _, row in behaviors.iterrows():\n",
        "        user_id = row['user_id']\n",
        "\n",
        "        # Clicked articles (positive examples)\n",
        "        clicked = [newsindex.get(aid, 0) for aid in row['article_ids_clicked'] if aid in newsindex]\n",
        "        # Non-clicked articles (negative examples)\n",
        "        inview = set(row['article_ids_inview'])\n",
        "        non_clicked = [newsindex.get(aid, 0) for aid in inview if aid in newsindex and aid not in row['article_ids_clicked']]\n",
        "\n",
        "        # User history\n",
        "        if user_id in user_history:\n",
        "            clickids = user_history[user_id][-MAX_HISTORY_LEN:]\n",
        "        else:\n",
        "            clickids = clicked[-MAX_HISTORY_LEN:]\n",
        "\n",
        "        for pos_doc in clicked:\n",
        "            neg_docs = newsample(non_clicked, npratio)\n",
        "            candidates = neg_docs + [pos_doc]\n",
        "            labels = [0] * npratio + [1]\n",
        "\n",
        "            # Shuffle candidates and labels\n",
        "            shuffle_indices = list(range(len(candidates)))\n",
        "            random.shuffle(shuffle_indices)\n",
        "            shuffled_candidates = [candidates[i] for i in shuffle_indices]\n",
        "            shuffled_labels = [labels[i] for i in shuffle_indices]\n",
        "\n",
        "            # Append training data\n",
        "            train_candidate.append(shuffled_candidates)\n",
        "            train_label.append(shuffled_labels)\n",
        "            train_user_his.append(clickids + [0] * (MAX_HISTORY_LEN - len(clickids)))\n",
        "\n",
        "    return train_candidate, train_label, train_user_his\n",
        "\n",
        "# Process train behaviors\n",
        "train_candidate, train_label, train_user_his = process_behaviors(train_behaviors, newsindex, history_train)\n",
        "val_candidate, val_label, val_user_his = process_behaviors(val_behaviors, newsindex, history_val)\n",
        "\n",
        "\"\"\" # Process validation behaviors\n",
        "val_candidate, val_user_his, val_labels, val_index = [], [], [], []\n",
        "for _, row in val_behaviors.iterrows():\n",
        "    user_id = row['user_id']\n",
        "    clicked = [newsindex.get(aid, 0) for aid in row['article_ids_clicked'] if aid in newsindex]\n",
        "    #inview = set(row['article_ids_inview'])\n",
        "    #non_clicked = [newsindex.get(aid, 0) for aid in inview if aid in newsindex and aid not in row['article_ids_clicked']]\n",
        "\n",
        "    user_history = clicked[-MAX_HISTORY_LEN:]\n",
        "    user_history = user_history + [0] * (MAX_HISTORY_LEN - len(user_history))\n",
        "\n",
        "\n",
        "    start_idx = len(val_candidate)\n",
        "\n",
        "    for aid in row['article_ids_inview']:\n",
        "        if aid in newsindex:\n",
        "            val_candidate.append(newsindex[aid])\n",
        "            val_user_his.append(user_history)\n",
        "            val_labels.append(1 if aid in row['article_ids_clicked'] else 0)\n",
        "\n",
        "    end_idx = len(val_candidate)\n",
        "    val_index.append([start_idx, end_idx]) \"\"\"\n",
        "\n",
        "# Print summary\n",
        "print(\"Training Data:\")\n",
        "print(\"Number of training candidates:\", len(train_candidate))\n",
        "print(\"Number of training labels:\", len(train_label))\n",
        "print(\"Number of user histories:\", len(train_user_his))\n",
        "\n",
        "print(\"\\nValidation Data:\")\n",
        "print(\"Number of validation candidates:\", len(val_candidate))\n",
        "print(\"Number of validation labels:\", len(val_label))\n",
        "print(\"Number of user histories:\", len(val_user_his))\n",
        "#print(\"Number of users in validation data:\", len(val_index))\n",
        "#print(\"Validation index ranges (start and end for each user):\")\n",
        "#for idx, (start, end) in enumerate(val_index):\n",
        "  #  print(f\"  User {idx + 1}: Start = {start}, End = {end}, Number of candidates = {end - start}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qYT4QYnAE4b",
        "outputId": "d19b5766-b98d-4739-e879-131cc017c6f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train and Validation data saved as Parquet files:\n",
            "  - train_data.parquet\n",
            "  - val_data.parquet\n"
          ]
        }
      ],
      "source": [
        "# Save Train Data\n",
        "train_df = pd.DataFrame({\n",
        "    'candidate': train_candidate,\n",
        "    'label': train_label,\n",
        "    'user_his': train_user_his\n",
        "})\n",
        "train_df.to_parquet('Data/train_data.parquet', index=False)\n",
        "\n",
        "# Save Validation Data\n",
        "val_df = pd.DataFrame({\n",
        "    'candidate': val_candidate,\n",
        "    'label': val_label,\n",
        "    'user_his': val_user_his\n",
        "})\n",
        "val_df.to_parquet('Data/val_data.parquet', index=False)\n",
        "\n",
        "# Print Confirmation\n",
        "print(\"Train and Validation data saved as Parquet files:\")\n",
        "print(\"  - train_data.parquet\")\n",
        "print(\"  - val_data.parquet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXwYYlW5AE4c",
        "outputId": "d4d17bc1-b861-44e3-cce4-eeb07f8891c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 16003\n",
            "Shape of padded news tensors: torch.Size([11778, 20])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Build vocabulary from tokenized titles\n",
        "vocab = {'<PAD>': 0}  # Start with a padding token\n",
        "for tokens in news.values():\n",
        "    for word in tokens:\n",
        "        if word not in vocab:\n",
        "            vocab[word] = len(vocab)\n",
        "\n",
        "# Convert titles to token indices\n",
        "news_tensor = {}\n",
        "for article_id, tokens in news.items():\n",
        "    token_indices = [vocab[word] for word in tokens]  # Convert words to token indices\n",
        "\n",
        "    # Truncate or pad to MAX_TITLE_LEN\n",
        "    if len(token_indices) > MAX_TITLE_LEN:\n",
        "        token_indices = token_indices[:MAX_TITLE_LEN]  # Truncate if too long\n",
        "    else:\n",
        "        token_indices += [0] * (MAX_TITLE_LEN - len(token_indices))  # Pad with zeros\n",
        "\n",
        "    news_tensor[newsindex[article_id]] = torch.tensor(token_indices, dtype=torch.long)\n",
        "    news_tensor[0] = torch.zeros(MAX_TITLE_LEN, dtype=torch.long)\n",
        "\n",
        "news_tensors_list = [tensor[:MAX_TITLE_LEN] for tensor in news_tensor.values()]  # Truncate to MAX_TITLE_LEN\n",
        "news_tensors_padded = pad_sequence(news_tensors_list, batch_first=True, padding_value=vocab['<PAD>'])\n",
        "\n",
        "# Example Output\n",
        "print(\"Vocabulary size:\", len(vocab))\n",
        "print(\"Shape of padded news tensors:\", news_tensors_padded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2X-EM-W_GbaK"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, data, news_tensor, max_history_len=50):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data (pd.DataFrame): DataFrame with 'candidate', 'label', and 'user_his'\n",
        "            news_tensor (dict): Dictionary mapping article_id to tokenized title tensors\n",
        "            max_history_len (int): Maximum length of user history (default: 50)\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.news_tensor = news_tensor\n",
        "        self.max_history_len = max_history_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "\n",
        "        # Candidate titles: List of tokenized article titles (positive + negatives)\n",
        "        candidate_ids = row['candidate']\n",
        "        candidate_titles = torch.stack([self.news_tensor[aid] for aid in candidate_ids])\n",
        "\n",
        "        # Labels: Positive (1) and negative (0) labels for candidates\n",
        "        labels = torch.tensor(row['label'], dtype=torch.float)\n",
        "\n",
        "        # User history: List of clicked articles converted to tokenized titles\n",
        "        user_his_ids = row['user_his']\n",
        "        user_his_titles = torch.stack([self.news_tensor[aid] for aid in user_his_ids])\n",
        "\n",
        "        # Pad user history if it's shorter than max length\n",
        "        if len(user_his_titles) < self.max_history_len:\n",
        "            padding = torch.zeros((self.max_history_len - len(user_his_titles), candidate_titles.shape[1]), dtype=torch.long)\n",
        "            user_his_titles = torch.cat((user_his_titles, padding), dim=0)\n",
        "\n",
        "        return candidate_titles, user_his_titles, labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMkKHoLbH23r",
        "outputId": "d2378ff5-2343-47bb-ff7d-af4105d3d8c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Candidate Titles Shape: torch.Size([32, 5, 20])\n",
            "User History Shape: torch.Size([32, 50, 20])\n",
            "Labels Shape: torch.Size([32, 5])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Load train and validation data\n",
        "train_data = pd.read_parquet('Data/train_data.parquet')\n",
        "val_data = pd.read_parquet('Data/val_data.parquet')\n",
        "\n",
        "# Initialize the Dataset for train and validation\n",
        "train_dataset = NewsDataset(train_data, news_tensor, max_history_len=50)\n",
        "val_dataset = NewsDataset(val_data, news_tensor, max_history_len=50)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Fetch a batch to test\n",
        "for candidate_titles, user_his_titles, labels in train_loader:\n",
        "    print(\"Candidate Titles Shape:\", candidate_titles.shape)  # (batch_size, num_candidates, MAX_TITLE_LEN)\n",
        "    print(\"User History Shape:\", user_his_titles.shape)      # (batch_size, max_history_len, MAX_TITLE_LEN)\n",
        "    print(\"Labels Shape:\", labels.shape)                    # (batch_size, num_candidates)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_IRBdxl-VjB9"
      },
      "outputs": [],
      "source": [
        "class NewsEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=300, num_heads=20, attention_hidden_dim=200):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            vocab_size (int): Size of the vocabulary\n",
        "            embedding_dim (int): Dimension of word embeddings\n",
        "            max_title_len (int): Maximum length of article titles\n",
        "        \"\"\"\n",
        "        super(NewsEncoder, self).__init__()\n",
        "\n",
        "        # Word Embedding Layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "\n",
        "        # Single-Head Self-Attention\n",
        "        self.multihead_attention = nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=num_heads, batch_first=True)\n",
        "\n",
        "        # Additive Attention Network\n",
        "        self.additive_attention_query = nn.Parameter(torch.randn(attention_hidden_dim))  # Query vector\n",
        "        self.additive_attention_fc1 = nn.Linear(embedding_dim, attention_hidden_dim)\n",
        "        self.additive_attention_fc2 = nn.Linear(attention_hidden_dim, 1)\n",
        "\n",
        "        # Linear Layer to output fixed-size vector\n",
        "        self.fc = nn.Linear(embedding_dim, embedding_dim)\n",
        "\n",
        "    def forward(self, title_tokens):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            title_tokens (Tensor): Shape (batch_size, max_title_len)\n",
        "                                   - Tokenized and padded title tensors\n",
        "        Returns:\n",
        "            Tensor: Fixed-size vector representing the article (batch_size, embedding_dim)\n",
        "        \"\"\"\n",
        "        # Step 1: Word Embedding\n",
        "        embedded = self.embedding(title_tokens)  # Shape: (batch_size, max_title_len, embedding_dim)\n",
        "\n",
        "        # Step 2: Multi-Head Self-Attention\n",
        "        attn_output, _ = self.multihead_attention(embedded, embedded, embedded)  # Shape: (batch_size, max_title_len, embedding_dim)\n",
        "\n",
        "        # Step 3: Additive Attention\n",
        "        additive_weights = torch.tanh(self.additive_attention_fc1(attn_output))  # Shape: (batch_size, max_title_len, attention_hidden_dim)\n",
        "        additive_scores = self.additive_attention_fc2(additive_weights).squeeze(-1)  # Shape: (batch_size, max_title_len)\n",
        "\n",
        "        # Compute attention weights (softmax over words)\n",
        "        attention_weights = torch.softmax(additive_scores, dim=1)  # Shape: (batch_size, max_title_len)\n",
        "\n",
        "        # Weighted sum of the attention outputs\n",
        "        weighted_sum = torch.sum(attn_output * attention_weights.unsqueeze(-1), dim=1)  # Shape: (batch_size, embedding_dim)\n",
        "\n",
        "        # Step 4: Linear Transformation\n",
        "        output_vector = self.fc(weighted_sum)  # Shape: (batch_size, embedding_dim)\n",
        "\n",
        "        return output_vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Onof3xGV2Jj",
        "outputId": "f6f4a786-ec47-4ffd-8d0f-f1077de30301"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of candidate_vectors: torch.Size([32, 5, 300])\n",
            "Shape of user_his_vectors: torch.Size([32, 50, 300])\n"
          ]
        }
      ],
      "source": [
        "# Define parameters\n",
        "VOCAB_SIZE = len(vocab)  # Vocabulary size\n",
        "EMBEDDING_DIM = 300      # Dimension of word embeddings\n",
        "MAX_TITLE_LEN = 20       # Length of padded titles\n",
        "\n",
        "# Initialize the News Encoder\n",
        "news_encoder = NewsEncoder(vocab_size=VOCAB_SIZE, embedding_dim=EMBEDDING_DIM)\n",
        "\n",
        "# Fetch a batch of candidate titles\n",
        "for candidate_titles, user_his_titles, labels in train_loader:\n",
        "    # Input shape: (batch_size, num_candidates, MAX_TITLE_LEN)\n",
        "    batch_size, num_candidates, title_len = candidate_titles.shape\n",
        "    _, max_history_len, _ = user_his_titles.shape\n",
        "\n",
        "    # Reshape to merge batch_size and num_candidates\n",
        "    candidate_titles_reshaped = candidate_titles.view(-1, title_len)  # Shape: (batch_size * num_candidates, MAX_TITLE_LEN)\n",
        "\n",
        "    # Pass through the News Encoder\n",
        "    candidate_vectors = news_encoder(candidate_titles_reshaped)  # Shape: (batch_size * num_candidates, EMBEDDING_DIM)\n",
        "\n",
        "    # Reshape back to original batch_size and num_candidates\n",
        "    candidate_vectors = candidate_vectors.view(batch_size, num_candidates, EMBEDDING_DIM)\n",
        "\n",
        "    # Reshape user history titles to merge batch_size and max_history_len\n",
        "    user_his_titles_reshaped = user_his_titles.view(-1, title_len)  # Shape: (batch_size * max_history_len, MAX_TITLE_LEN)\n",
        "\n",
        "    # Pass through News Encoder\n",
        "    user_his_vectors = news_encoder(user_his_titles_reshaped)  # Shape: (batch_size * max_history_len, EMBEDDING_DIM)\n",
        "\n",
        "    # Reshape back to original batch_size and max_history_len\n",
        "    user_his_vectors = user_his_vectors.view(batch_size, max_history_len, EMBEDDING_DIM)  # Shape: (batch_size, max_history_len, EMBEDDING_DIM)\n",
        "\n",
        "    print(\"Shape of candidate_vectors:\", candidate_vectors.shape)  # Expected: (batch_size, num_candidates, EMBEDDING_DIM)\n",
        "    print(\"Shape of user_his_vectors:\", user_his_vectors.shape)    # Expected: (batch_size, max_history_len, EMBEDDING_DIM)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "cp28oe4emula"
      },
      "outputs": [],
      "source": [
        "class UserEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim=300, num_heads=20, attention_hidden_dim=200):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            embedding_dim (int): Dimension of the article embeddings\n",
        "            num_heads (int): Number of attention heads in multi-head attention\n",
        "            attention_hidden_dim (int): Dimension of the query vector in additive attention\n",
        "        \"\"\"\n",
        "        super(UserEncoder, self).__init__()\n",
        "\n",
        "        # Multi-Head Self-Attention\n",
        "        self.multihead_attention = nn.MultiheadAttention(embed_dim=embedding_dim,\n",
        "                                                         num_heads=num_heads,\n",
        "                                                         batch_first=True)\n",
        "\n",
        "        # Additive Attention\n",
        "        self.additive_attention_query = nn.Parameter(torch.randn(attention_hidden_dim))  # Learnable query vector\n",
        "        self.additive_attention_fc1 = nn.Linear(embedding_dim, attention_hidden_dim)\n",
        "        self.additive_attention_fc2 = nn.Linear(attention_hidden_dim, 1)\n",
        "\n",
        "    def forward(self, user_his_vectors):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            user_his_vectors (Tensor): Shape (batch_size, max_history_len, embedding_dim)\n",
        "                                        - Representations of clicked articles\n",
        "        Returns:\n",
        "            Tensor: User representation vector (batch_size, embedding_dim)\n",
        "        \"\"\"\n",
        "        # Step 1: Multi-Head Self-Attention\n",
        "        attn_output, _ = self.multihead_attention(user_his_vectors, user_his_vectors, user_his_vectors)\n",
        "        # Shape: (batch_size, max_history_len, embedding_dim)\n",
        "\n",
        "        # Step 2: Additive Attention\n",
        "        additive_weights = torch.tanh(self.additive_attention_fc1(attn_output))  # Shape: (batch_size, max_history_len, attention_hidden_dim)\n",
        "        additive_scores = self.additive_attention_fc2(additive_weights).squeeze(-1)  # Shape: (batch_size, max_history_len)\n",
        "\n",
        "        # Compute attention weights (softmax over user history)\n",
        "        attention_weights = torch.softmax(additive_scores, dim=1)  # Shape: (batch_size, max_history_len)\n",
        "\n",
        "        # Weighted sum of the attention outputs\n",
        "        user_vector = torch.sum(attn_output * attention_weights.unsqueeze(-1), dim=1)  # Shape: (batch_size, embedding_dim)\n",
        "\n",
        "        return user_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGPAfQQdm2B1",
        "outputId": "ec97f152-fbb4-4a87-d3b3-7642c4cfae40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of user_his_vectors: torch.Size([32, 50, 300])\n",
            "Shape of user_vectors: torch.Size([32, 300])\n"
          ]
        }
      ],
      "source": [
        "# Define parameters\n",
        "EMBEDDING_DIM = 300      # Dimension of article embeddings\n",
        "NUM_HEADS = 20           # Number of attention heads\n",
        "ATTENTION_HIDDEN_DIM = 200  # Query vector dimension for additive attention\n",
        "\n",
        "# Initialize User Encoder\n",
        "user_encoder = UserEncoder(embedding_dim=EMBEDDING_DIM, num_heads=NUM_HEADS, attention_hidden_dim=ATTENTION_HIDDEN_DIM)\n",
        "\n",
        "# Fetch a batch of user history vectors\n",
        "for candidate_titles, user_his_titles, labels in train_loader:\n",
        "    # Reshape user history titles to merge batch_size and max_history_len\n",
        "    user_his_titles_reshaped = user_his_titles.view(-1, MAX_TITLE_LEN)  # Shape: (batch_size * max_history_len, MAX_TITLE_LEN)\n",
        "\n",
        "    # Pass through News Encoder to get user history vectors\n",
        "    user_his_vectors = news_encoder(user_his_titles_reshaped)  # Shape: (batch_size * max_history_len, EMBEDDING_DIM)\n",
        "\n",
        "    # Reshape back to (batch_size, max_history_len, EMBEDDING_DIM)\n",
        "    batch_size, max_history_len, _ = user_his_titles.shape\n",
        "    user_his_vectors = user_his_vectors.view(batch_size, max_history_len, EMBEDDING_DIM)\n",
        "\n",
        "    # Pass user history vectors through User Encoder\n",
        "    user_vectors = user_encoder(user_his_vectors)  # Shape: (batch_size, EMBEDDING_DIM)\n",
        "\n",
        "    print(\"Shape of user_his_vectors:\", user_his_vectors.shape)  # (batch_size, max_history_len, EMBEDDING_DIM)\n",
        "    print(\"Shape of user_vectors:\", user_vectors.shape)         # (batch_size, EMBEDDING_DIM)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-lKkpluuYQhg"
      },
      "outputs": [],
      "source": [
        "class NRMSModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=300, num_heads=20, attention_hidden_dim=200, max_history_len=50):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            vocab_size (int): Size of the vocabulary\n",
        "            embedding_dim (int): Dimension of word embeddings\n",
        "            num_heads (int): Number of attention heads in multi-head attention\n",
        "            attention_hidden_dim (int): Dimension of the query vector in additive attention\n",
        "            max_history_len (int): Maximum length of user history\n",
        "            max_title_len (int): Maximum length of article titles\n",
        "        \"\"\"\n",
        "        super(NRMSModel, self).__init__()\n",
        "\n",
        "        # News Encoder for both candidate and user history articles\n",
        "        self.news_encoder = NewsEncoder(vocab_size=vocab_size,\n",
        "                                         embedding_dim=embedding_dim,\n",
        "                                         num_heads=num_heads,\n",
        "                                         attention_hidden_dim=attention_hidden_dim)\n",
        "\n",
        "        # User Encoder to encode user history into a single user representation vector\n",
        "        self.user_encoder = UserEncoder(embedding_dim=embedding_dim,\n",
        "                                         num_heads=num_heads,\n",
        "                                         attention_hidden_dim=attention_hidden_dim)\n",
        "\n",
        "    def forward(self, candidate_titles, user_his_titles):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            candidate_titles (Tensor): Shape (batch_size, num_candidates, max_title_len)\n",
        "                                       - Tokenized and padded titles of candidate articles\n",
        "            user_his_titles (Tensor): Shape (batch_size, max_history_len, max_title_len)\n",
        "                                       - Tokenized and padded titles of user clicked articles\n",
        "        Returns:\n",
        "            Tensor: Click scores for each candidate article (batch_size, num_candidates)\n",
        "        \"\"\"\n",
        "        batch_size, num_candidates, max_title_len = candidate_titles.shape\n",
        "        _, max_history_len, _ = user_his_titles.shape\n",
        "\n",
        "        # -------------------\n",
        "        # Process Candidate Articles\n",
        "        # -------------------\n",
        "        # Reshape candidates to merge batch_size and num_candidates\n",
        "        candidate_titles_reshaped = candidate_titles.view(-1, max_title_len)  # Shape: (batch_size * num_candidates, max_title_len)\n",
        "\n",
        "        # Encode candidate articles\n",
        "        candidate_vectors = self.news_encoder(candidate_titles_reshaped)  # Shape: (batch_size * num_candidates, embedding_dim)\n",
        "\n",
        "        # Reshape back to original batch_size and num_candidates\n",
        "        candidate_vectors = candidate_vectors.view(batch_size, num_candidates, -1)  # Shape: (batch_size, num_candidates, embedding_dim)\n",
        "\n",
        "        # -------------------\n",
        "        # Process User History\n",
        "        # -------------------\n",
        "        # Reshape user history titles to merge batch_size and max_history_len\n",
        "        user_his_titles_reshaped = user_his_titles.view(-1, max_title_len)  # Shape: (batch_size * max_history_len, max_title_len)\n",
        "\n",
        "        # Encode user history articles\n",
        "        user_his_vectors = self.news_encoder(user_his_titles_reshaped)  # Shape: (batch_size * max_history_len, embedding_dim)\n",
        "\n",
        "        # Reshape back to original batch_size and max_history_len\n",
        "        user_his_vectors = user_his_vectors.view(batch_size, max_history_len, -1)  # Shape: (batch_size, max_history_len, embedding_dim)\n",
        "\n",
        "        # Encode user history into a single user representation vector\n",
        "        user_vectors = self.user_encoder(user_his_vectors)  # Shape: (batch_size, embedding_dim)\n",
        "\n",
        "        # -------------------\n",
        "        # Compute Click Scores\n",
        "        # -------------------\n",
        "        # Dot product between user vector and candidate vectors\n",
        "        click_scores = torch.bmm(candidate_vectors, user_vectors.unsqueeze(-1)).squeeze(-1)  # Shape: (batch_size, num_candidates)\n",
        "\n",
        "        return click_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN9u_oUyYj8n",
        "outputId": "6257d9d8-9387-4c45-c4a7-109da5727e12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of click_scores: torch.Size([32, 5])\n",
            "Example click scores: tensor([-0.0106, -0.0193, -0.0229, -0.0140, -0.0102],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Initialize the NRMS Model\n",
        "nrms_model = NRMSModel(vocab_size=VOCAB_SIZE,\n",
        "                       embedding_dim=EMBEDDING_DIM,\n",
        "                       num_heads=NUM_HEADS,\n",
        "                       attention_hidden_dim=ATTENTION_HIDDEN_DIM,\n",
        "                       max_history_len=50)\n",
        "\n",
        "# Fetch a batch from the DataLoader\n",
        "for candidate_titles, user_his_titles, labels in train_loader:\n",
        "    # Pass through NRMS model\n",
        "    click_scores = nrms_model(candidate_titles, user_his_titles)  # Shape: (batch_size, num_candidates)\n",
        "\n",
        "    print(\"Shape of click_scores:\", click_scores.shape)  # Expected: (batch_size, num_candidates)\n",
        "    print(\"Example click scores:\", click_scores[0])     # Print scores for the first user in the batch\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ih1vq5zcBSm",
        "outputId": "0afb8d84-f4f0-4375-da1d-76cc46592f60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "User 1:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: græder sig selv i søvn\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0104\n",
            "Candidate 2:\n",
            "  Title: smed vigtige point : kan skrive historie\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0144\n",
            "Candidate 3:\n",
            "  Title: forsvaret varsler støjgener og militærkøretøjer på vejene i nordsjælland\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0199\n",
            "Candidate 4:\n",
            "  Title: utroligt : disse svampe 'taler ' sammen efter regnskyl\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0142\n",
            "Candidate 5:\n",
            "  Title: sejr sender dortmund på mesterskabskurs\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0138\n",
            "\n",
            "User 2:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: luksus-konkurs undersøges : offentlige millioner væltede ind\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0024\n",
            "Candidate 2:\n",
            "  Title: dmi : teltfesterne er reddet\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0060\n",
            "Candidate 3:\n",
            "  Title: vanvidspris : det dyreste danske nogensinde\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0228\n",
            "Candidate 4:\n",
            "  Title: knivstikkeri i fælledparken : en anholdt og sigtet\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0040\n",
            "Candidate 5:\n",
            "  Title: se det her : vild luksus før million-kollaps\n",
            "  Label: 0.0\n",
            "  Click Score: 0.0030\n",
            "\n",
            "User 3:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: sår tvivl om naviair-forklaring : lyver de ?\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0123\n",
            "Candidate 2:\n",
            "  Title: afviste nøgenbilleder i playboy\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0069\n",
            "Candidate 3:\n",
            "  Title: forfatter bag børnebog om sorg anklages for drab på ægtemand\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0025\n",
            "Candidate 4:\n",
            "  Title: redder liv til daglig : - det var noget helt andet\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0180\n",
            "Candidate 5:\n",
            "  Title: efter stort karriereskifte : er ikke på vej tilbage\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0133\n",
            "\n",
            "User 4:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: kæmpe forvirring : zelenskyj irettesat af talsmand\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0191\n",
            "Candidate 2:\n",
            "  Title: overrasker med gennemsigtig top : viser bryster på den røde løber\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0066\n",
            "Candidate 3:\n",
            "  Title: bro gak-gak i frederikssund : kan ikke tåle solen\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0087\n",
            "Candidate 4:\n",
            "  Title: slår alarm : - på randen af katastrofe\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0113\n",
            "Candidate 5:\n",
            "  Title: putins inderkreds : vestens fortabte håb\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0070\n",
            "\n",
            "User 5:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: vanvittigt fund i rustvogn : 51-årig mand dømt\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0095\n",
            "Candidate 2:\n",
            "  Title: stort slag for fcn : marcondes færdig for sæsonen\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0122\n",
            "Candidate 3:\n",
            "  Title: ikke alle bliver til noget\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0149\n",
            "Candidate 4:\n",
            "  Title: efterretninger : putins mænd er skeptiske\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0069\n",
            "Candidate 5:\n",
            "  Title: passagerer i chok : hitler-hyldest i intercity-tog\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0224\n",
            "\n",
            "User 6:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: sådan er emilie meng-sigtets fængselsliv\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0080\n",
            "Candidate 2:\n",
            "  Title: vanvidspris : det dyreste danske nogensinde\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0234\n",
            "Candidate 3:\n",
            "  Title: slår op med kæresten\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0083\n",
            "Candidate 4:\n",
            "  Title: putins hemmelige redskab : de skal dræbe ukraines præsident\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0074\n",
            "Candidate 5:\n",
            "  Title: er din penis skrumpet ? derfor sker det\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0138\n",
            "\n",
            "User 7:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: kritik af gratis studenterbajere\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0126\n",
            "Candidate 2:\n",
            "  Title: fck-boss med øl-forbud : der bliver ingen fest\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0211\n",
            "Candidate 3:\n",
            "  Title: 30 år efter 113 skud : - jeg var 'betjenten '\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0161\n",
            "Candidate 4:\n",
            "  Title: officielt : vender tilbage i ikonisk rolle\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0169\n",
            "Candidate 5:\n",
            "  Title: usa : vil ramme putins 'krigsmaskine '\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0039\n",
            "\n",
            "User 8:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: gulddrama intakt efter var-drama\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0016\n",
            "Candidate 2:\n",
            "  Title: nu kommer regnen : her falder der mest\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0043\n",
            "Candidate 3:\n",
            "  Title: storklub får fratrukket ti point\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0037\n",
            "Candidate 4:\n",
            "  Title: utroligt : 7.000 år gammel vej opdaget på havets bund\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0200\n",
            "Candidate 5:\n",
            "  Title: politiet efterlyser overfaldsmand med bæltetaske og guldkæde\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0093\n",
            "\n",
            "User 9:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: voldsomt skyderi i mexico : ti døde og ni sårede\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0190\n",
            "Candidate 2:\n",
            "  Title: voldsomt solouheld : to unge mænd kørt til riget\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0113\n",
            "Candidate 3:\n",
            "  Title: lufthavnskaos : her er dine rettigheder\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0015\n",
            "Candidate 4:\n",
            "  Title: putin hylder wagner-gruppen : ukraine afviser\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0008\n",
            "Candidate 5:\n",
            "  Title: vild milepæl : - havde ikke tænkt over det\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0147\n",
            "\n",
            "User 10:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: mester i løftebrud\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0159\n",
            "Candidate 2:\n",
            "  Title: drabstiltalt til agenten : 'du har jo også stukket en kvinde ned '\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0133\n",
            "Candidate 3:\n",
            "  Title: tyskland slukker drømmen : danmark færdig ved vm\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0201\n",
            "Candidate 4:\n",
            "  Title: derfor er rocker jaget vildt\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0180\n",
            "Candidate 5:\n",
            "  Title: efterforsker sag som drabsforsøg : mand anholdt\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0103\n",
            "\n",
            "User 11:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: flere dårlige nyheder til viktor fischer i sverige\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0061\n",
            "Candidate 2:\n",
            "  Title: 14 døde i italien\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0179\n",
            "Candidate 3:\n",
            "  Title: synger om usund afhængighed\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0019\n",
            "Candidate 4:\n",
            "  Title: dansk landsholdsspiller stopper i juventus\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0076\n",
            "Candidate 5:\n",
            "  Title: kendt youtuber misbrugt af folk bag byfest : der var ingen aftale\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0144\n",
            "\n",
            "User 12:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: forsvaret varsler støjgener og militærkøretøjer på vejene i nordsjælland\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0239\n",
            "Candidate 2:\n",
            "  Title: slut : - tak til min mor\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0199\n",
            "Candidate 3:\n",
            "  Title: vulkanudbrud lammer flytrafikken\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0133\n",
            "Candidate 4:\n",
            "  Title: narkokartel ville voldtage og dræbe 11-årig datter : - vi flygtede samme nat\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0115\n",
            "Candidate 5:\n",
            "  Title: slut : ekstase i parken !\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0072\n",
            "\n",
            "User 13:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: afslører : så mange plastikoperationer har jeg fået\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0074\n",
            "Candidate 2:\n",
            "  Title: usa : ukraine stod sandsynligvis bag orkestreret kreml-angreb\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0111\n",
            "Candidate 3:\n",
            "  Title: trump sagsøgt : nu slår hun til igen\n",
            "  Label: 0.0\n",
            "  Click Score: 0.0062\n",
            "Candidate 4:\n",
            "  Title: desantis lover at støtte bitcoin og give fbi-direktør sparket\n",
            "  Label: 0.0\n",
            "  Click Score: 0.0045\n",
            "Candidate 5:\n",
            "  Title: trumps møgsager : påståede affærer og fbi-ransagning\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0093\n",
            "\n",
            "User 14:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: to biler braget sammen : vej spærret i begge retninger\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0242\n",
            "Candidate 2:\n",
            "  Title: fck hårdt ramt : må undvære flere stjerner\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0071\n",
            "Candidate 3:\n",
            "  Title: flammehav i roskilde : politi og brandvæsen til stede\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0139\n",
            "Candidate 4:\n",
            "  Title: slut : - tak til min mor\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0179\n",
            "Candidate 5:\n",
            "  Title: christiane : jeg fik en taknemmelighed for livet\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0036\n",
            "\n",
            "User 15:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: - det her er paradis\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0166\n",
            "Candidate 2:\n",
            "  Title: vognmænd vil lave flere aktioner efter lastbilblokade\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0142\n",
            "Candidate 3:\n",
            "  Title: ciao , casper ! holger er den nye konge af norden\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0093\n",
            "Candidate 4:\n",
            "  Title: advarer : brug dem ikke\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0104\n",
            "Candidate 5:\n",
            "  Title: prostatalægen : sådan lever jeg selv\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0065\n",
            "\n",
            "User 16:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: leos død bliver til tv\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0079\n",
            "Candidate 2:\n",
            "  Title: multimillionær stoppet i vildt flugtforsøg\n",
            "  Label: 1.0\n",
            "  Click Score: 0.0001\n",
            "Candidate 3:\n",
            "  Title: forsvarer om drabstiltalt : - higede efter anerkendelse og 'street credit '\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0182\n",
            "Candidate 4:\n",
            "  Title: skræmmende antal t-rex-dinosaurer på jorden\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0021\n",
            "Candidate 5:\n",
            "  Title: dansk ægtepar anholdt på græsk ferieø\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0120\n",
            "\n",
            "User 17:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: prisvindende dansk film er blevet suspenderet i rusland\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0041\n",
            "Candidate 2:\n",
            "  Title: knivstikkeri i fælledparken : en anholdt og sigtet\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0119\n",
            "Candidate 3:\n",
            "  Title: slår op med kæresten\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0095\n",
            "Candidate 4:\n",
            "  Title: wagner-chef afviser russiske meldinger om fremgang\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0110\n",
            "Candidate 5:\n",
            "  Title: mark le fêvre afslører : det ser du ikke i 'stormester '\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0047\n",
            "\n",
            "User 18:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: 20 danskere : vi elsker vores nøgne kroppe\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0148\n",
            "Candidate 2:\n",
            "  Title: who-direktør håber på historisk pandemiaftale ved verdenssamling\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0007\n",
            "Candidate 3:\n",
            "  Title: terrortiltalt 16-årig : dagbog afslører hans dybeste hemmeligheder\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0019\n",
            "Candidate 4:\n",
            "  Title: kvadratmeter-snyd : vandt i retten\n",
            "  Label: 1.0\n",
            "  Click Score: 0.0010\n",
            "Candidate 5:\n",
            "  Title: ny teori : særligt kulhydrat kan have vild effekt\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0155\n",
            "\n",
            "User 19:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: fck-boss med øl-forbud : der bliver ingen fest\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0219\n",
            "Candidate 2:\n",
            "  Title: boligsalg taber pusten og når laveste aprilniveau siden 2014\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0055\n",
            "Candidate 3:\n",
            "  Title: gældskrise i usa : 'alle familier bør være bekymret '\n",
            "  Label: 0.0\n",
            "  Click Score: 0.0011\n",
            "Candidate 4:\n",
            "  Title: huse i flammer\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0083\n",
            "Candidate 5:\n",
            "  Title: google begynder at lukke konti : sletter alt\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0167\n",
            "\n",
            "User 20:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: skræmmende antal t-rex-dinosaurer på jorden\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0015\n",
            "Candidate 2:\n",
            "  Title: en ældre dronning skal pryde nye mønter\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0005\n",
            "Candidate 3:\n",
            "  Title: barn mistænkt for at stå bag tragisk dødsfald\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0135\n",
            "Candidate 4:\n",
            "  Title: ny og nem trend : nul sex i tre år\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0228\n",
            "Candidate 5:\n",
            "  Title: det er aldrig sket før\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0095\n",
            "\n",
            "User 21:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: legende takker af : - andre havde opgivet ham\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0184\n",
            "Candidate 2:\n",
            "  Title: kæmpe byttehandel : nu er de størst\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0008\n",
            "Candidate 3:\n",
            "  Title: ny sundhedspakke : statsministeriet indkalder til pressemøde\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0048\n",
            "Candidate 4:\n",
            "  Title: nye beskyldninger : ukraine afviser angreb på grænsepost\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0067\n",
            "Candidate 5:\n",
            "  Title: bro gak-gak i frederikssund : kan ikke tåle solen\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0104\n",
            "\n",
            "User 22:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: smed arsenal mesterskabet på grund af hende ?\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0099\n",
            "Candidate 2:\n",
            "  Title: strejke , sexafpresning og sort magi : historien om verdens bedste landshold\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0194\n",
            "Candidate 3:\n",
            "  Title: sådan falder du i søvn på 120 sekunder\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0099\n",
            "Candidate 4:\n",
            "  Title: 49 kvinder smider tøjet : det perfekte er en illusion\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0101\n",
            "Candidate 5:\n",
            "  Title: fredagsfuser : nye dr-satsninger flopper fælt\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0003\n",
            "\n",
            "User 23:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: kæmpe giro-drama : vild gyser på toppen\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0147\n",
            "Candidate 2:\n",
            "  Title: dansk rekord-præstation på mount everest : - de gjorde det sgu\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0227\n",
            "Candidate 3:\n",
            "  Title: anholdt som serie-belurer\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0153\n",
            "Candidate 4:\n",
            "  Title: dette vitamin kan du nøjes med\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0118\n",
            "Candidate 5:\n",
            "  Title: trusler og bedragerianklager : dansk tv-profil i byggekaos\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0108\n",
            "\n",
            "User 24:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: overlægen anna har sex med mænd , kvinder og par\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0076\n",
            "Candidate 2:\n",
            "  Title: kampfly styrter ned i spanien\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0188\n",
            "Candidate 3:\n",
            "  Title: motivation til leeds : vil vise sine bryster\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0139\n",
            "Candidate 4:\n",
            "  Title: kæmpe resultat for frank og co .\n",
            "  Label: 1.0\n",
            "  Click Score: 0.0003\n",
            "Candidate 5:\n",
            "  Title: holger rune knækker rival og buldrer i finale i rom\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0061\n",
            "\n",
            "User 25:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: - hvordan skal jeg svare på det ?\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0099\n",
            "Candidate 2:\n",
            "  Title: efter drama : viser sig sammen for første gang\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0062\n",
            "Candidate 3:\n",
            "  Title: 22-årig sigtet for narkokørsel : kørte 150 km/t på strandvejen\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0073\n",
            "Candidate 4:\n",
            "  Title: ekstra bladet i mexico : - de tog alle vores penge\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0240\n",
            "Candidate 5:\n",
            "  Title: forstå reglerne : sådan undgår du at blive snydt i lufthavnen\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0078\n",
            "\n",
            "User 26:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: jasmin åbner op om brud : - pisse hårdt\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0194\n",
            "Candidate 2:\n",
            "  Title: alex vanopslagh : - jeg får stadig angstanfald\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0107\n",
            "Candidate 3:\n",
            "  Title: se den vilde liste : her er de rigeste britiske stjerner\n",
            "  Label: 0.0\n",
            "  Click Score: 0.0006\n",
            "Candidate 4:\n",
            "  Title: fc midtjylland besejrer aab i isaksen-show\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0233\n",
            "Candidate 5:\n",
            "  Title: vildt vejr før holgers brag\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0169\n",
            "\n",
            "User 27:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: stripshow foran 2000 ansatte : undskyld !\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0019\n",
            "Candidate 2:\n",
            "  Title: til angreb på smukfest : - man må gerne sige 'skrigeskinke '\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0100\n",
            "Candidate 3:\n",
            "  Title: kendisser hængt ud i nøgengruppe\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0154\n",
            "Candidate 4:\n",
            "  Title: dansk realitydeltager : smider kludene hos onlyfans-konkurrent\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0154\n",
            "Candidate 5:\n",
            "  Title: 18-årig skoleskyder forsøgte at slå sin mormor ihjel : bor stadig i huset\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0198\n",
            "\n",
            "User 28:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: person stukket med kniv\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0115\n",
            "Candidate 2:\n",
            "  Title: den falske telefon-myte : du skal ikke gøre det\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0077\n",
            "Candidate 3:\n",
            "  Title: stjerner i sorg : hylder tina turner\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0098\n",
            "Candidate 4:\n",
            "  Title: vækker opsigt på natklub : haaland festede i dyr pyjamas\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0267\n",
            "Candidate 5:\n",
            "  Title: gennemsigtig kjole på den røde løber : derfor gør hun det\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0124\n",
            "\n",
            "User 29:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: finale i coppa italia : fiorentina - inter\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0259\n",
            "Candidate 2:\n",
            "  Title: skandaløse scener : stjerne smidt ud efter raserianfald\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0137\n",
            "Candidate 3:\n",
            "  Title: trist dansk måling : trivslen daler i folkeskolerne\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0130\n",
            "Candidate 4:\n",
            "  Title: aktier : disse fejl koster nybegyndere dyrt\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0118\n",
            "Candidate 5:\n",
            "  Title: multimillionær stoppet i vildt flugtforsøg\n",
            "  Label: 1.0\n",
            "  Click Score: 0.0017\n",
            "\n",
            "User 30:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: troede det var løgn\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0221\n",
            "Candidate 2:\n",
            "  Title: britisk forfatter fra gylden generation er død\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0042\n",
            "Candidate 3:\n",
            "  Title: italiensk redningsmission gik galt : fire sårede\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0100\n",
            "Candidate 4:\n",
            "  Title: forgæves : putins 'vasketrick ' fortsætter\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0074\n",
            "Candidate 5:\n",
            "  Title: manchester city er engelsk mester efter arsenal-nederlag\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0113\n",
            "\n",
            "User 31:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: earth , wind & fire-guitarist er død\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0077\n",
            "Candidate 2:\n",
            "  Title: rusland advarer : vil reagere 'prompte og ekstremt hårdt ' på nye angreb\n",
            "  Label: 0.0\n",
            "  Click Score: 0.0026\n",
            "Candidate 3:\n",
            "  Title: stjernen læste om sin død på nettet\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0065\n",
            "Candidate 4:\n",
            "  Title: dansk aktie styrtdykker\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0075\n",
            "Candidate 5:\n",
            "  Title: opdagede du det ? jesper vollmer slemt forbrændt\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0196\n",
            "\n",
            "User 32:\n",
            "------------------------------\n",
            "Candidate 1:\n",
            "  Title: - vi skal oppe os\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0116\n",
            "Candidate 2:\n",
            "  Title: enden er nær for ikonisk film-saga : er du klar til årets største action-brag ?\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0037\n",
            "Candidate 3:\n",
            "  Title: to danskere færdige ved ishockey-vm\n",
            "  Label: 1.0\n",
            "  Click Score: -0.0070\n",
            "Candidate 4:\n",
            "  Title: bom-smart frederiksen\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0091\n",
            "Candidate 5:\n",
            "  Title: populært kæledyr blev pludselig forbudt : nu skal de dø\n",
            "  Label: 0.0\n",
            "  Click Score: -0.0080\n"
          ]
        }
      ],
      "source": [
        "# Define a function to decode tokenized titles back into text\n",
        "def decode_title(token_indices, vocab):\n",
        "    reverse_vocab = {idx: word for word, idx in vocab.items()}  # Reverse the vocabulary\n",
        "    return \" \".join([reverse_vocab[idx] for idx in token_indices if idx != 0])  # Ignore padding tokens (0)\n",
        "\n",
        "# Fetch a batch from the DataLoader\n",
        "for candidate_titles, user_his_titles, labels in train_loader:\n",
        "    # Pass through NRMS model\n",
        "    click_scores = nrms_model(candidate_titles, user_his_titles)  # Shape: (batch_size, num_candidates)\n",
        "\n",
        "    # Loop through the batch\n",
        "    batch_size, num_candidates, max_title_len = candidate_titles.shape\n",
        "    for i in range(batch_size):\n",
        "        print(f\"\\nUser {i + 1}:\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        # Decode and print each candidate title, its label, and its score\n",
        "        for j in range(num_candidates):\n",
        "            title_tokens = candidate_titles[i, j].cpu().numpy()  # Get token indices for the title\n",
        "            title_text = decode_title(title_tokens, vocab)  # Decode the title back into text\n",
        "            label = labels[i, j].item()  # Get the label\n",
        "            score = click_scores[i, j].item()  # Get the click score\n",
        "\n",
        "            print(f\"Candidate {j + 1}:\")\n",
        "            print(f\"  Title: {title_text}\")\n",
        "            print(f\"  Label: {label}\")\n",
        "            print(f\"  Click Score: {score:.4f}\")\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTZNQTuy3muU",
        "outputId": "5f01e83f-5496-4606-fe45-76a3a0892c36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3], Batch [1/778], Loss: 1.6085\n",
            "Epoch [1/3], Batch [101/778], Loss: 1.5199\n",
            "Epoch [1/3], Batch [201/778], Loss: 1.5525\n",
            "Epoch [1/3], Batch [301/778], Loss: 1.4732\n",
            "Epoch [1/3], Batch [401/778], Loss: 1.5538\n",
            "Epoch [1/3], Batch [501/778], Loss: 1.5504\n",
            "Epoch [1/3], Batch [601/778], Loss: 1.6320\n",
            "Epoch [1/3], Batch [701/778], Loss: 1.5083\n",
            "Epoch [1/3] - Average Loss: 1.5365\n",
            "Epoch [2/3], Batch [1/778], Loss: 1.4675\n",
            "Epoch [2/3], Batch [101/778], Loss: 1.6041\n",
            "Epoch [2/3], Batch [201/778], Loss: 1.5301\n",
            "Epoch [2/3], Batch [301/778], Loss: 1.4145\n",
            "Epoch [2/3], Batch [401/778], Loss: 1.4568\n",
            "Epoch [2/3], Batch [501/778], Loss: 1.3658\n",
            "Epoch [2/3], Batch [601/778], Loss: 1.4816\n",
            "Epoch [2/3], Batch [701/778], Loss: 1.4121\n",
            "Epoch [2/3] - Average Loss: 1.4664\n",
            "Epoch [3/3], Batch [1/778], Loss: 1.4108\n",
            "Epoch [3/3], Batch [101/778], Loss: 1.4033\n",
            "Epoch [3/3], Batch [201/778], Loss: 1.5279\n",
            "Epoch [3/3], Batch [301/778], Loss: 1.4058\n",
            "Epoch [3/3], Batch [401/778], Loss: 1.3647\n",
            "Epoch [3/3], Batch [501/778], Loss: 1.5076\n",
            "Epoch [3/3], Batch [601/778], Loss: 1.5788\n",
            "Epoch [3/3], Batch [701/778], Loss: 1.2884\n",
            "Epoch [3/3] - Average Loss: 1.4414\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define parameters\n",
        "NUM_EPOCHS = 3          # Number of epochs\n",
        "LEARNING_RATE = 1e-4    # Learning rate\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Initialize the model, loss, and optimizer\n",
        "nrms_model = NRMSModel(vocab_size=VOCAB_SIZE,\n",
        "                       embedding_dim=EMBEDDING_DIM,\n",
        "                       num_heads=NUM_HEADS,\n",
        "                       attention_hidden_dim=ATTENTION_HIDDEN_DIM,\n",
        "                       max_history_len=50).to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  # Loss function\n",
        "optimizer = optim.Adam(nrms_model.parameters(), lr=LEARNING_RATE)  # Optimizer\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    nrms_model.train()  # Set model to training mode\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, (candidate_titles, user_his_titles, labels) in enumerate(train_loader):\n",
        "        # Move data to the appropriate device (GPU/CPU)\n",
        "        candidate_titles = candidate_titles.to(DEVICE)  # Shape: (batch_size, num_candidates, max_title_len)\n",
        "        user_his_titles = user_his_titles.to(DEVICE)    # Shape: (batch_size, max_history_len, max_title_len)\n",
        "        labels = torch.argmax(labels, dim=1).to(DEVICE)  # Convert labels to indices, Shape: (batch_size)\n",
        "\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        click_scores = nrms_model(candidate_titles, user_his_titles)  # Shape: (batch_size, num_candidates)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(click_scores, labels)  # CrossEntropyLoss expects (scores, target_indices)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print progress for every 100 batches\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f\"Epoch [{epoch + 1}/{NUM_EPOCHS}], Batch [{batch_idx + 1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # Print epoch loss\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch + 1}/{NUM_EPOCHS}] - Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "print(\"Training complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "zNTA8oBgXM2a"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "def validate_model(model, val_loader, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    all_scores = []\n",
        "\n",
        "    with torch.no_grad():  # No gradient computation during evaluation\n",
        "        for batch_idx, (candidate_titles, user_his_titles, labels) in enumerate(val_loader):\n",
        "            # Move data to the appropriate device\n",
        "            candidate_titles = candidate_titles.to(device)  # Shape: (batch_size, num_candidates, max_title_len)\n",
        "            user_his_titles = user_his_titles.to(device)    # Shape: (batch_size, max_history_len, max_title_len)\n",
        "            labels = torch.argmax(labels, dim=1).to(device)  # Convert labels to indices, Shape: (batch_size)\n",
        "\n",
        "            # Forward pass\n",
        "            click_scores = model(candidate_titles, user_his_titles)  # Shape: (batch_size, num_candidates)\n",
        "\n",
        "            # Predicted indices (max score per candidate set)\n",
        "            preds = torch.argmax(click_scores, dim=1).cpu().numpy()  # Shape: (batch_size)\n",
        "\n",
        "            # Append true labels and predictions for metrics\n",
        "            all_labels.extend(labels.cpu().numpy())  # True labels\n",
        "            all_preds.extend(preds)  # Predicted labels\n",
        "            all_scores.extend(torch.softmax(click_scores, dim=1).cpu().numpy())  # Softmax probabilities\n",
        "\n",
        "    print(f\"Shape of all_labels: {len(all_labels)}\")  # Should match the total number of validation samples\n",
        "    print(f\"Shape of all_scores: {len(all_scores), len(all_scores[0])}\")  # Should be (n_samples, n_classes)\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    auc = roc_auc_score(all_labels, all_scores, multi_class=\"ovr\")  # Use full softmax scores\n",
        "\n",
        "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Validation AUC: {auc:.4f}\")\n",
        "    return accuracy, auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9Z5TyEGXNe_",
        "outputId": "253c210d-8a51-4f17-ac4c-76c4feb63d64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of all_labels: 25505\n",
            "Shape of all_scores: (25505, 5)\n",
            "Validation Accuracy: 0.2205\n",
            "Validation AUC: 0.5598\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.22050578317976868, 0.5598350127392537)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test the trained model\n",
        "validate_model(nrms_model, val_loader, DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "aG3H5hszcYCp"
      },
      "outputs": [],
      "source": [
        "torch.save(nrms_model.state_dict(), \"/content/drive/MyDrive/DTU/Kandidat/Semester 9/Deep learning/Final project/Data/nrms_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvFVzJDcckAP",
        "outputId": "21324dd0-e8fb-46bb-8017-4a0384ac3515"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-27-3ba86ca2f9e7>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  nrms_model.load_state_dict(torch.load(\"/content/drive/MyDrive/DTU/Kandidat/Semester 9/Deep learning/Final project/Data/nrms_model.pth\"))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "NRMSModel(\n",
              "  (news_encoder): NewsEncoder(\n",
              "    (embedding): Embedding(16003, 300, padding_idx=0)\n",
              "    (multihead_attention): MultiheadAttention(\n",
              "      (out_proj): NonDynamicallyQuantizableLinear(in_features=300, out_features=300, bias=True)\n",
              "    )\n",
              "    (additive_attention_fc1): Linear(in_features=300, out_features=200, bias=True)\n",
              "    (additive_attention_fc2): Linear(in_features=200, out_features=1, bias=True)\n",
              "    (fc): Linear(in_features=300, out_features=300, bias=True)\n",
              "  )\n",
              "  (user_encoder): UserEncoder(\n",
              "    (multihead_attention): MultiheadAttention(\n",
              "      (out_proj): NonDynamicallyQuantizableLinear(in_features=300, out_features=300, bias=True)\n",
              "    )\n",
              "    (additive_attention_fc1): Linear(in_features=300, out_features=200, bias=True)\n",
              "    (additive_attention_fc2): Linear(in_features=200, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nrms_model = NRMSModel(vocab_size=VOCAB_SIZE,\n",
        "                       embedding_dim=EMBEDDING_DIM,\n",
        "                       num_heads=NUM_HEADS,\n",
        "                       attention_hidden_dim=ATTENTION_HIDDEN_DIM,\n",
        "                       max_history_len=50).to(DEVICE)\n",
        "nrms_model.load_state_dict(torch.load(\"/content/drive/MyDrive/DTU/Kandidat/Semester 9/Deep learning/Final project/Data/nrms_model.pth\"))\n",
        "nrms_model.eval()  # Set model to evaluation mode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTh9CXb7XPN-",
        "outputId": "b237b6b3-e7b6-427d-bcdf-43451f86abb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "User 1:\n",
            "True Label: 0\n",
            "Predicted Click Probabilities: [0.3590598  0.03104732 0.28306085 0.06200203 0.26483008]\n",
            "\n",
            "User 2:\n",
            "True Label: 0\n",
            "Predicted Click Probabilities: [0.1983009  0.19637354 0.04171867 0.5255394  0.03806753]\n",
            "\n",
            "User 3:\n",
            "True Label: 4\n",
            "Predicted Click Probabilities: [0.2089105  0.2769646  0.15376191 0.20774192 0.15262102]\n",
            "\n",
            "User 4:\n",
            "True Label: 1\n",
            "Predicted Click Probabilities: [0.18161696 0.09691916 0.3208212  0.188273   0.21236964]\n",
            "\n",
            "User 5:\n",
            "True Label: 0\n",
            "Predicted Click Probabilities: [0.18593705 0.27698404 0.36308143 0.08882122 0.08517627]\n",
            "\n",
            "User 6:\n",
            "True Label: 2\n",
            "Predicted Click Probabilities: [0.20987754 0.07774509 0.2166143  0.33537588 0.16038722]\n",
            "\n",
            "User 7:\n",
            "True Label: 2\n",
            "Predicted Click Probabilities: [0.16927657 0.0018787  0.4383322  0.10109434 0.2894182 ]\n",
            "\n",
            "User 8:\n",
            "True Label: 4\n",
            "Predicted Click Probabilities: [0.15353468 0.27252963 0.14342271 0.13682663 0.2936864 ]\n",
            "\n",
            "User 9:\n",
            "True Label: 4\n",
            "Predicted Click Probabilities: [0.23732632 0.16111258 0.14569937 0.17779927 0.2780625 ]\n",
            "\n",
            "User 10:\n",
            "True Label: 3\n",
            "Predicted Click Probabilities: [0.15245424 0.21471769 0.14576435 0.1608614  0.3262023 ]\n",
            "\n",
            "User 11:\n",
            "True Label: 4\n",
            "Predicted Click Probabilities: [0.24341863 0.15889119 0.31156683 0.2368604  0.04926295]\n",
            "\n",
            "User 12:\n",
            "True Label: 2\n",
            "Predicted Click Probabilities: [0.00912911 0.35700658 0.14239053 0.21226273 0.27921098]\n",
            "\n",
            "User 13:\n",
            "True Label: 1\n",
            "Predicted Click Probabilities: [0.19898483 0.18074735 0.24866803 0.2209314  0.15066841]\n",
            "\n",
            "User 14:\n",
            "True Label: 4\n",
            "Predicted Click Probabilities: [0.14750119 0.34779269 0.07819489 0.15903082 0.2674804 ]\n",
            "\n",
            "User 15:\n",
            "True Label: 2\n",
            "Predicted Click Probabilities: [0.03240912 0.28008002 0.19016851 0.08664936 0.41069302]\n",
            "\n",
            "User 16:\n",
            "True Label: 1\n",
            "Predicted Click Probabilities: [0.19537556 0.20098917 0.23997593 0.21247497 0.15118442]\n",
            "\n",
            "User 17:\n",
            "True Label: 0\n",
            "Predicted Click Probabilities: [0.265825   0.1722535  0.41168508 0.01558144 0.134655  ]\n",
            "\n",
            "User 18:\n",
            "True Label: 2\n",
            "Predicted Click Probabilities: [0.03332162 0.03419606 0.46301657 0.09142693 0.37803885]\n",
            "\n",
            "User 19:\n",
            "True Label: 1\n",
            "Predicted Click Probabilities: [0.20825522 0.14676616 0.11543872 0.27169976 0.25784016]\n",
            "\n",
            "User 20:\n",
            "True Label: 0\n",
            "Predicted Click Probabilities: [0.22847106 0.22709589 0.15106627 0.24960129 0.14376542]\n",
            "\n",
            "User 21:\n",
            "True Label: 2\n",
            "Predicted Click Probabilities: [0.10456029 0.3286959  0.33591947 0.16329524 0.06752905]\n",
            "\n",
            "User 22:\n",
            "True Label: 0\n",
            "Predicted Click Probabilities: [0.3201071  0.09276019 0.12797378 0.27752385 0.18163505]\n",
            "\n",
            "User 23:\n",
            "True Label: 0\n",
            "Predicted Click Probabilities: [0.16534127 0.18218343 0.24329993 0.23409167 0.17508362]\n",
            "\n",
            "User 24:\n",
            "True Label: 0\n",
            "Predicted Click Probabilities: [0.35055086 0.19865067 0.17147136 0.14617677 0.13315038]\n",
            "\n",
            "User 25:\n",
            "True Label: 3\n",
            "Predicted Click Probabilities: [0.315008   0.03404719 0.29523924 0.18448003 0.17122553]\n",
            "\n",
            "User 26:\n",
            "True Label: 4\n",
            "Predicted Click Probabilities: [0.05229037 0.25528464 0.01823081 0.39401886 0.28017536]\n",
            "\n",
            "User 27:\n",
            "True Label: 1\n",
            "Predicted Click Probabilities: [0.32782152 0.12416115 0.14462298 0.16924596 0.2341484 ]\n",
            "\n",
            "User 28:\n",
            "True Label: 4\n",
            "Predicted Click Probabilities: [0.22052875 0.29087415 0.04654601 0.15545046 0.2866007 ]\n",
            "\n",
            "User 29:\n",
            "True Label: 4\n",
            "Predicted Click Probabilities: [0.359757   0.20055754 0.19223823 0.11807571 0.12937148]\n",
            "\n",
            "User 30:\n",
            "True Label: 3\n",
            "Predicted Click Probabilities: [0.20996223 0.2510642  0.22432593 0.18780856 0.12683907]\n",
            "\n",
            "User 31:\n",
            "True Label: 3\n",
            "Predicted Click Probabilities: [0.14234895 0.21152194 0.32028088 0.0449497  0.28089854]\n",
            "\n",
            "User 32:\n",
            "True Label: 2\n",
            "Predicted Click Probabilities: [0.01175773 0.03913284 0.26283604 0.4457219  0.24055152]\n"
          ]
        }
      ],
      "source": [
        "# Inspect click probabilities\n",
        "for batch_idx, (candidate_titles, user_his_titles, labels) in enumerate(val_loader):\n",
        "    candidate_titles = candidate_titles.to(DEVICE)\n",
        "    user_his_titles = user_his_titles.to(DEVICE)\n",
        "    labels = torch.argmax(labels, dim=1).to(DEVICE)\n",
        "\n",
        "    # Forward pass\n",
        "    click_scores = nrms_model(candidate_titles, user_his_titles)\n",
        "    softmax_probs = torch.softmax(click_scores, dim=1)\n",
        "\n",
        "    for i in range(candidate_titles.size(0)):  # Iterate over the batch\n",
        "        print(f\"\\nUser {i + 1}:\")\n",
        "        print(f\"True Label: {labels[i].item()}\")\n",
        "        print(f\"Predicted Click Probabilities: {softmax_probs[i].cpu().detach().numpy()}\")\n",
        "    break  # Remove this to inspect the full dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZ2q5HBKYmVL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
